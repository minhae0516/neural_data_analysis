{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "updated 2019-08-09 \n",
    "written by Minhae Kwon\n",
    "Multinomial logistic regression for \"Decoding\" process\n",
    "ref: https://chrisalbon.com/machine_learning/naive_bayes/multinomial_logistic_regression/\n",
    "\n",
    "\n",
    "ver 3.0: try use Kernel Ridge Regression\n",
    "\n",
    "ver 2.0: try use Radial Basis Function for nonlinear transform (manually)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from pandas import DataFrame, read_csv\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_SIZE = 0.2  # ratio of test data set \n",
    "N_SPLITS = 3 # \"K\" in K-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#if you use neural data\n",
    "bb_df = read_csv('./data/bb_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_prev = read_csv('./data/recoding_bb_prev_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_now = read_csv('./data/recoding_bb_now_df.csv') #behavior belief =[belief for box1, beleif for box2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if you use pomdp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('./data/pomdp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df_raw = data[['box1 belief', 'box2 belief','location']].to_numpy()#[:10000]\n",
    "a_df = data['action'].to_numpy()#[:10000]\n",
    "\n",
    "X = nb_df_raw\n",
    "y = a_df\n",
    "\n",
    "# rescale beleif in order to make a same distance to location\n",
    "X[:,:2] = X[:,:2]*10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there are 3 types of data: test data, train data, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr = LinearRegression() # linear regression is used for encoding process\n",
    "regr = KernelRidge(alpha=0.01, gamma=0.1, kernel='rbf') # linear regression(small gamma) with RBF kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use only train data \n",
    "# why use StratifiedKFold?: The folds are made by preserving the percentage of samples for each class.\n",
    "k_fold = StratifiedKFold(n_splits=N_SPLITS) # seperate train data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why argmax(1)? split cannot simply handle multidimension y. \n",
    "# ref: https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\n",
    "for train_index, val_index in k_fold.split(X_train, y_train):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    x_train_kf, x_val_kf = X[train_index], X[val_index]\n",
    "    y_train_kf, y_val_kf = y[train_index], y[val_index]\n",
    "    #print(x_train_kf)\n",
    "    #print(y_train_kf)\n",
    "    regr.fit(x_train_kf, y_train_kf) # fit the model\n",
    "    pred = regr.predict(x_val_kf) # predict based on current model -> use validation data for evaluation\n",
    "    #print(pred)\n",
    "    #print(y_val_kf)\n",
    "    print('score', r2_score(y_val_kf, pred, multioutput='raw_values')) # get r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.dual_coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_X_test = regr.predict(X_test)\n",
    "\n",
    "\n",
    "decoding_accuracy = sum(y_test - predic_X_test)/y_test.shape[0] \n",
    "# true == estimate\n",
    "print('decoding_accuracy[%]:', decoding_accuracy*100)\n",
    "print('score', r2_score(y_test, predic_X_test, multioutput='raw_values'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#recoding_error = (y_test - predic_X_test)**2 # true - estimate\n",
    "#print('Mean squared error: \\n', np.mean(recoding_error, axis=0))\n",
    "#print('squared error std:\\n', np.std(recoding_error, axis=0))\n",
    "#print('score', r2_score(y_test, predic_X_test, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot: compare raw data vs prediction\n",
    "#plt.scatter(a_df_test, a_dec_test, s=0.005, c='blue', marker='o')\n",
    "plt.hist2d(y_test[:], predic_X_test[:], bins=(5,5), cmap=plt.cm.Greys)\n",
    "plt.colorbar()\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('estimated')\n",
    "plt.title('decoding: test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x = np.linspace(0,4,num=11)\n",
    "line_y = np.linspace(0,4,num=11)\n",
    "\n",
    "\n",
    "# plot: compare raw data vs prediction\n",
    "plt.scatter(y_test[:], predic_X_test[:], s=3, c='blue', marker='o')\n",
    "plt.plot(line_x, line_y,c='k')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('prediction')\n",
    "plt.title('decoding')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xedges = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "yedges = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "H, xedges, yedges = np.histogram2d(y_test, predic_X_test, bins=(xedges, yedges))\n",
    "H = H.T  # Let each row list bins with common y range.\n",
    "print(H)\n",
    "print(np.sum(H,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same plot with the above black and white figure\n",
    "plt.imshow(H, interpolation='nearest', origin='low', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('The number of selections')\n",
    "plt.xlabel('Behavioral policy (true action)') \n",
    "plt.ylabel('Neural decoding (estimated action)')\n",
    "plt.title('Decoding: unormalzied heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(H/np.sum(H,axis=0), interpolation='nearest', origin='low', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('selected ratio')\n",
    "plt.xlabel('Behavioral policy (true action)') \n",
    "plt.ylabel('Neural decoding (estimated action)')\n",
    "plt.title('Decoding: normalized heatmap)')\n",
    "plt.savefig('./figures/decoding_KRR.eps', format = 'eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#neural estimate of belief using current linear regression model\\nnb= regr.predict(r_df) \\nnb_df = DataFrame(nb, columns = bb_df.columns)\\n#save neural estimate belief\\nnb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#neural estimate of belief using current linear regression model\n",
    "nb= regr.predict(r_df) \n",
    "nb_df = DataFrame(nb, columns = bb_df.columns)\n",
    "#save neural estimate belief\n",
    "nb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
