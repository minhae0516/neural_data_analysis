{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "updated 2019-08-08 \n",
    "written by Minhae Kwon\n",
    "\n",
    "- `recoding`: Estimate the next belief from current belief and observations\n",
    "    - input:\n",
    "        - if you use POMDP data (for now): `recoding_pomdp_all_prev_df.csv` and `recoding_pomdp_all_now_df.csv`\n",
    "        - ideally with neural data: `recoding_neural_all_prev_df.csv` and `recoding_neural_all_now_df.csv`\n",
    "    - output: `recoding_belief_results_df.csv` (estimated future belief)\n",
    "    - method: Autoregression - this is linear regression between two time steps. \n",
    "    - there are two versions in codes:\n",
    "        -`recoding_wo_RBF.ipynb`: no RBF is used. \n",
    "        - `recoding_KRR.ipynb`: RBF is used using sklearn built-in function: [Kernel Ridge Regression (kernel ='rbf')](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html). \n",
    "        (Warning: this code runs pretty slow compared to others. So if you need to handle big data size, plan in advance!)\n",
    "        - `recoding_manualRBF.ipynb`: RBF is manually coded by me. So we can customize center locations for nonlinear transform. \n",
    "        Everything is the same as `recoding_wo_RBF.ipynb` but RBF.\n",
    "        - `recoding_KRR.ipynb` works the best, and pretty good!\n",
    "\n",
    "ref: https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n",
    "https://scikit-learn.org/stable/auto_examples/plot_kernel_ridge_regression.html#sphx-glr-auto-examples-plot-kernel-ridge-regression-py\n",
    "\n",
    "ref: https://chrisalbon.com/machine_learning/linear_regression/linear_regression_using_scikit-learn/\n",
    "     https://datatofish.com/multiple-linear-regression-python/\n",
    "\n",
    "cross validate score: Coefficient of determination\n",
    "https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\"\"\"\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "#bb_df = read_csv('./data/bb_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_prev = read_csv('./data/recoding_pomdp_all_prev_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_now = read_csv('./data/recoding_pomdp_all_now_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.2  # ratio of test data set \n",
    "N_SPLITS = 10 # \"K\" in K-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bb_df_prev #.to_numpy()\n",
    "y_raw = bb_df_now[['behavior_belief1', 'behavior_belief2']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF(X_set, centers):\n",
    "    \"\"\"\n",
    "    gamma = 0.01: hard indicator\n",
    "    gamma = 0.1: soft indicator\n",
    "    \"\"\"\n",
    "    X_RBF_set = np.ones((X_set.shape[0], centers.shape[0])) # number of data set * number of center ponts\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set[i] #i-th data\n",
    "        X_RBF = np.exp(-1*1/gamma/2*np.linalg.norm(X-centers,2, axis = 1)**2)        \n",
    "        X_RBF_set[i] = X_RBF/np.sum(X_RBF)# divided by total sum -> make total sum 1\n",
    "        #print(X_RBF/np.sum(X_RBF))\n",
    "    return X_RBF_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_raw = data[['behavior_belief1', 'behavior_belief2']].to_numpy()#[:1000] # for time constraint, I tested only 1000 data points\n",
    "\n",
    "a_raw = data['action'].to_numpy()#[:1000]\n",
    "loc_raw = data['location'].to_numpy()#[:1000]\n",
    "rwd_raw = data['reward'].to_numpy()\n",
    "clr_raw = data[['color 1', 'color 2']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "b_center = np.linspace(0.05,1.05,11)[:10]\n",
    "a_center = np.array([0,1,2,3,4])\n",
    "loc_center = np.array([0, 1, 2])\n",
    "rwd_center = np.array([0, 1])\n",
    "clr_center = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# make distance =1 for belief\n",
    "nb_raw = nb_raw*10\n",
    "b_center = b_center*10\n",
    "y_raw = y_raw*10\n",
    "\n",
    "centers_a = []\n",
    "centers_b = []\n",
    "centers_loc =[]\n",
    "centers_rwd = []\n",
    "centers_clr =[]\n",
    "\n",
    "\n",
    "for i in itertools.product(b_center,b_center):\n",
    "    centers_b.append(i)\n",
    "for j in itertools.product(loc_center):\n",
    "    centers_loc.append(j)\n",
    "for k in itertools.product(rwd_center):\n",
    "    centers_rwd.append(k)\n",
    "for c in itertools.product(clr_center, clr_center):\n",
    "    centers_clr.append(c)\n",
    "for l in itertools.product(a_center):\n",
    "    centers_a.append(l)\n",
    "    \n",
    "centers_b = np.array(centers_b)\n",
    "centers_loc = np.array(centers_loc)\n",
    "centers_rwd = np.array(centers_rwd)\n",
    "centers_clr = np.array(centers_clr)\n",
    "centers_a = np.array(centers_a)\n",
    "\n",
    "# nonlinear transform using RBF: belief and location are transformed individually\n",
    "# gamma in here is the variance term in gaussian equation\n",
    "nb = RBF(nb_raw, centers_b, gamma=0.1) \n",
    "loc = RBF(loc_raw, centers_loc, gamma=0.01) # very small gamma to act as a spike (hard indicator)\n",
    "rwd = RBF(rwd_raw, centers_rwd, gamma=0.01) # very small gamma to act as a spike (hard indicator)\n",
    "clr = RBF(clr_raw, centers_clr, gamma=0.01)# very small gamma to act as a spike (hard indicator)\n",
    "a = RBF(a_raw, centers_a, gamma=0.01)# very small gamma to act as a spike (hard indicator)\n",
    "y = RBF(y_raw, centers_b, gamma=0.1) \n",
    "\n",
    "\n",
    "nb_all = np.concatenate((nb, a, loc, rwd, clr),axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_set=[]\n",
    "X_set =  np.array([[1.,1.],[1.5, 1.5]])\n",
    "X_set.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb = RBF(X_set, centers_b, gamma=0.1) \n",
    "print(nb)\n",
    "#print('sum:',np.sum(nb,axis=1))\n",
    "nb*(nb>0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nb_all\n",
    "y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there are 3 types of data: test data, train data, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(n_jobs = -1) # linear regression is used for encoding process\n",
    "#regr = KernelRidge(alpha=0.01, gamma=0.1, kernel='rbf') # linear regression(small gamma) with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use only train data \n",
    "# why use StratifiedKFold?: The folds are made by preserving the percentage of samples for each class.\n",
    "k_fold = StratifiedKFold(n_splits=N_SPLITS) # seperate train data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.02834868 0.03751387 0.04936315 0.05310418 0.05203923 0.04107929\n",
      " 0.04783944 0.05041713 0.07532169 0.08759665 0.04528266 0.01543424\n",
      " 0.02467838 0.02810022 0.01425654 0.00797148 0.02311463 0.02638726\n",
      " 0.03438885 0.05556347 0.03564266 0.02936776 0.02384628 0.03158474\n",
      " 0.02665354 0.02859846 0.03366694 0.02146147 0.04453201 0.06855033\n",
      " 0.04771441 0.04215685 0.0247486  0.02108798 0.02350251 0.01474047\n",
      " 0.02029422 0.01110468 0.02631451 0.05793184 0.04078537 0.0297959\n",
      " 0.02327545 0.02950568 0.01700252 0.02073154 0.0302635  0.02415017\n",
      " 0.02382824 0.06186104 0.04311048 0.02122905 0.02319599 0.02971328\n",
      " 0.03381354 0.02027588 0.01351779 0.01943669 0.03041594 0.05860508\n",
      " 0.03745183 0.02430265 0.02146798 0.01829601 0.01530347 0.02303746\n",
      " 0.01722472 0.02531999 0.02431607 0.04608401 0.05216363 0.0269536\n",
      " 0.02400769 0.01163497 0.02154324 0.01938802 0.01303181 0.01769002\n",
      " 0.0213431  0.06435936 0.07408567 0.03986947 0.03163146 0.02407577\n",
      " 0.02968104 0.02653249 0.02341039 0.02717141 0.03295251 0.07751235\n",
      " 0.09765927 0.07024337 0.04450556 0.0511409  0.04344207 0.0530618\n",
      " 0.0452424  0.04269048 0.04983308 0.11689165]\n",
      "score [0.02131808 0.03992703 0.04449924 0.03374053 0.03499536 0.03746955\n",
      " 0.05475207 0.05550892 0.06004907 0.10189811 0.03804496 0.03906164\n",
      " 0.02218566 0.03095659 0.02763091 0.04995138 0.03059995 0.02410252\n",
      " 0.04050027 0.07521136 0.03544034 0.03317921 0.02820973 0.03369661\n",
      " 0.03757615 0.02469413 0.02699096 0.029518   0.04417408 0.091987\n",
      " 0.03884882 0.02592487 0.03606343 0.01150756 0.01974208 0.02619857\n",
      " 0.01992785 0.03594298 0.03401882 0.04801128 0.04214684 0.03768309\n",
      " 0.02509808 0.02418555 0.02349578 0.01403516 0.02461588 0.01977324\n",
      " 0.02538546 0.07129004 0.04777771 0.02877608 0.02314615 0.0170636\n",
      " 0.01176854 0.01677629 0.01610056 0.02549818 0.02820601 0.04946852\n",
      " 0.03571423 0.03565637 0.01135578 0.02437402 0.02760308 0.01793327\n",
      " 0.01247632 0.02591338 0.0224605  0.06031694 0.05074133 0.02596114\n",
      " 0.02435064 0.02257287 0.01873136 0.01484496 0.02130278 0.01295108\n",
      " 0.02048146 0.04801025 0.07771571 0.04577568 0.03591079 0.02435862\n",
      " 0.01798456 0.02616411 0.02763528 0.02028299 0.03488501 0.07474301\n",
      " 0.1104245  0.06577989 0.0684552  0.0566378  0.04884627 0.04091071\n",
      " 0.03878458 0.05408379 0.0560044  0.10348964]\n",
      "score [0.02449463 0.04040724 0.04443314 0.0454707  0.03914281 0.04186372\n",
      " 0.05640849 0.06127595 0.07546606 0.09708188 0.03204334 0.0341213\n",
      " 0.02644713 0.01406317 0.03153248 0.04955189 0.02415274 0.03175879\n",
      " 0.0510088  0.06320054 0.03986082 0.02656859 0.0262354  0.03143436\n",
      " 0.03484816 0.02351167 0.02765869 0.03194412 0.04350431 0.07545856\n",
      " 0.05542076 0.03160122 0.02093003 0.02429015 0.01246479 0.03199483\n",
      " 0.02209971 0.02356209 0.03309097 0.05629182 0.04085467 0.0357547\n",
      " 0.01883557 0.0245659  0.02203626 0.02251214 0.02044694 0.02157158\n",
      " 0.02575721 0.0560956  0.04503509 0.03520567 0.02694762 0.02599733\n",
      " 0.00698762 0.01002315 0.02245096 0.0218084  0.02550264 0.06055783\n",
      " 0.04640406 0.03424608 0.02882758 0.0320529  0.01966244 0.014572\n",
      " 0.01728466 0.02095747 0.02208396 0.0569673  0.05513807 0.02680212\n",
      " 0.02573007 0.01878324 0.02442877 0.02744051 0.01427372 0.01749408\n",
      " 0.02871123 0.05841318 0.07941255 0.040676   0.02676079 0.03172458\n",
      " 0.02638425 0.02210144 0.0252599  0.02453652 0.02812898 0.06709319\n",
      " 0.10046303 0.06256192 0.05320361 0.05916207 0.0438728  0.04664446\n",
      " 0.0530336  0.04844079 0.0585845  0.11690596]\n",
      "score [0.0203442  0.03478003 0.04202976 0.04935991 0.04293105 0.03977517\n",
      " 0.04171948 0.05569743 0.06949411 0.0890574  0.04679422 0.02461095\n",
      " 0.04429618 0.03183276 0.02308271 0.05274    0.02460275 0.03159475\n",
      " 0.03073883 0.0760714  0.03391355 0.02542327 0.01423594 0.01997617\n",
      " 0.03411904 0.02826239 0.02667782 0.0324642  0.03520499 0.08799503\n",
      " 0.03261198 0.01814276 0.03397444 0.01354898 0.01559523 0.01570417\n",
      " 0.03384219 0.03817769 0.02623094 0.07467354 0.04018281 0.03485292\n",
      " 0.03055744 0.0271311  0.02265903 0.02981943 0.02541321 0.02887734\n",
      " 0.02296191 0.04650027 0.04839822 0.02884571 0.01646145 0.01853623\n",
      " 0.02404842 0.02127743 0.02264551 0.01040404 0.01808074 0.06626833\n",
      " 0.04883765 0.04367627 0.03195428 0.01863862 0.02666597 0.01648662\n",
      " 0.01791306 0.02443225 0.03260049 0.06106423 0.05447521 0.030069\n",
      " 0.02123307 0.01622911 0.02115229 0.03753092 0.01085818 0.00964786\n",
      " 0.03136453 0.04951048 0.0688631  0.02800018 0.03702185 0.02503566\n",
      " 0.01503284 0.02856103 0.02475898 0.01669441 0.03286457 0.06857955\n",
      " 0.0795637  0.06728198 0.0536496  0.05507794 0.0421906  0.05015586\n",
      " 0.03500525 0.0501203  0.06169589 0.13026847]\n",
      "score [0.01684924 0.0432164  0.0429305  0.03860703 0.03482666 0.04619445\n",
      " 0.04160565 0.04256138 0.05647125 0.09585584 0.03452822 0.02701801\n",
      " 0.04808986 0.02707252 0.02338322 0.04046544 0.02236627 0.02691085\n",
      " 0.03543219 0.0799709  0.02501786 0.03444205 0.01616099 0.02704265\n",
      " 0.03093364 0.04011498 0.02272956 0.02118181 0.03811634 0.07420195\n",
      " 0.03168267 0.0210402  0.01361277 0.03384822 0.01462765 0.02343856\n",
      " 0.02253455 0.02262919 0.02813516 0.06043034 0.04484794 0.02851614\n",
      " 0.0236617  0.01076882 0.02191916 0.02322895 0.02074158 0.03281171\n",
      " 0.01803786 0.0511093  0.03945298 0.02403652 0.02870441 0.03006338\n",
      " 0.02356671 0.01249482 0.02004053 0.02298289 0.02920541 0.04838099\n",
      " 0.04823938 0.03893066 0.0314012  0.02232935 0.02454102 0.02282174\n",
      " 0.02012522 0.02048116 0.02590833 0.05090539 0.0561108  0.03112906\n",
      " 0.01658116 0.01841648 0.01316818 0.02244872 0.01873916 0.01922448\n",
      " 0.02710556 0.04367117 0.07493986 0.036526   0.02699901 0.02924002\n",
      " 0.02784525 0.0239381  0.02497498 0.02479625 0.0317786  0.06782133\n",
      " 0.0966083  0.06124703 0.05695154 0.05092774 0.03863986 0.04032026\n",
      " 0.04210182 0.03497254 0.06046893 0.10486888]\n",
      "score [0.02728388 0.0384105  0.04002569 0.04410765 0.05843626 0.04555522\n",
      " 0.05661198 0.05971274 0.07007855 0.09322605 0.0427673  0.03161716\n",
      " 0.02271356 0.02124701 0.02349696 0.02411858 0.03034174 0.02171525\n",
      " 0.03723934 0.06323164 0.0269352  0.04062108 0.02955521 0.03799798\n",
      " 0.04076953 0.04301488 0.02202187 0.02281157 0.04292693 0.07540826\n",
      " 0.03434866 0.0256039  0.02323683 0.02375431 0.03211946 0.02405769\n",
      " 0.02066378 0.02494976 0.0343517  0.063941   0.03547626 0.03458004\n",
      " 0.02110674 0.00730124 0.02299123 0.01542979 0.02116926 0.02971336\n",
      " 0.02812418 0.0538729  0.03602395 0.03715817 0.01446908 0.01379167\n",
      " 0.01910935 0.01009094 0.01727387 0.03226208 0.02694767 0.04397662\n",
      " 0.0523855  0.02893303 0.02467898 0.0252041  0.00619643 0.02687585\n",
      " 0.01794927 0.00784698 0.01980927 0.05951976 0.06301109 0.0279303\n",
      " 0.02655376 0.02028319 0.02783746 0.0283071  0.02098787 0.02052866\n",
      " 0.02894095 0.0482646  0.0695312  0.03321237 0.03355282 0.03049177\n",
      " 0.02267183 0.03194755 0.02189419 0.02935072 0.03161989 0.07015694\n",
      " 0.10566348 0.06495771 0.05141791 0.04296394 0.0587408  0.04902819\n",
      " 0.04205653 0.04366887 0.07164449 0.11466172]\n",
      "score [0.03142606 0.03866371 0.04779826 0.05020355 0.05365797 0.04441681\n",
      " 0.04397514 0.0600146  0.07262373 0.08571718 0.03866004 0.03667204\n",
      " 0.02543601 0.01596469 0.02336319 0.00672299 0.03513653 0.02671717\n",
      " 0.04926966 0.06078988 0.03685027 0.03340444 0.02068891 0.02334241\n",
      " 0.03076423 0.02198154 0.02906482 0.03246595 0.04302423 0.06885915\n",
      " 0.03697217 0.02755872 0.01909822 0.01492342 0.02291045 0.02965193\n",
      " 0.02116082 0.0368473  0.0346746  0.05978181 0.03226317 0.0400769\n",
      " 0.02790476 0.02370868 0.01361731 0.03149985 0.01397689 0.02441119\n",
      " 0.02942482 0.05746145 0.04373625 0.04584606 0.02531238 0.01810464\n",
      " 0.02158912 0.02644827 0.02313073 0.01691254 0.01307381 0.04253291\n",
      " 0.04636675 0.03795885 0.01840347 0.02590633 0.02468042 0.01699099\n",
      " 0.01689416 0.0108866  0.03005295 0.05983949 0.05324949 0.02608265\n",
      " 0.02495797 0.02074886 0.02211868 0.03195252 0.01687295 0.02349221\n",
      " 0.02137404 0.0607302  0.07213014 0.04115096 0.0320474  0.02760177\n",
      " 0.02886078 0.02155594 0.02860127 0.02100216 0.03328307 0.0556345\n",
      " 0.09672324 0.06552496 0.05666079 0.04816188 0.04102073 0.04784458\n",
      " 0.04621544 0.04222045 0.0580431  0.1178447 ]\n",
      "score [0.01122508 0.02920555 0.04201871 0.04968596 0.05360403 0.04749252\n",
      " 0.0462265  0.05751665 0.07536145 0.0887318  0.03914864 0.01602426\n",
      " 0.03040225 0.02681849 0.03754065 0.04773502 0.02955224 0.03099378\n",
      " 0.03757017 0.07925746 0.03764782 0.03321676 0.02965613 0.03576429\n",
      " 0.02442638 0.02890316 0.02366267 0.02849257 0.04891482 0.08405415\n",
      " 0.04019393 0.02330556 0.02821341 0.02373312 0.0310454  0.01967108\n",
      " 0.01952727 0.02424769 0.03041065 0.06482013 0.03949013 0.02667589\n",
      " 0.01814192 0.02115971 0.03582078 0.01696887 0.01485832 0.02055805\n",
      " 0.01903613 0.07144625 0.03787061 0.04074742 0.02997169 0.0293289\n",
      " 0.01769576 0.0081887  0.0227408  0.02091132 0.02600927 0.05046895\n",
      " 0.05875716 0.0231757  0.02725746 0.02142463 0.02807724 0.01530968\n",
      " 0.02042097 0.02033599 0.02428027 0.05355751 0.05034029 0.03109415\n",
      " 0.02079266 0.01572325 0.0227058  0.02801692 0.02047077 0.01205133\n",
      " 0.02688617 0.042046   0.07074437 0.03669437 0.03365733 0.0279006\n",
      " 0.02806515 0.03154631 0.02817304 0.01862698 0.03046339 0.07368244\n",
      " 0.09100871 0.05347202 0.05395443 0.05897031 0.04599546 0.03636887\n",
      " 0.04930914 0.03987303 0.06153756 0.13169887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.02805974 0.03880263 0.03490025 0.04859495 0.0498657  0.02654735\n",
      " 0.04309018 0.04924115 0.07012897 0.10258217 0.024181   0.0483617\n",
      " 0.02637739 0.02802489 0.01504735 0.02878345 0.02500288 0.02079122\n",
      " 0.03775633 0.08540212 0.02288551 0.03572401 0.02724968 0.02740285\n",
      " 0.03064195 0.02507623 0.02748482 0.025291   0.03906871 0.08248979\n",
      " 0.04491818 0.03616248 0.0296699  0.02493582 0.0150647  0.02041142\n",
      " 0.01969195 0.03150235 0.03302956 0.04343725 0.04493217 0.02726539\n",
      " 0.01680435 0.01521863 0.0085663  0.02012086 0.01983225 0.01836139\n",
      " 0.03239639 0.05358422 0.05082991 0.02438552 0.01510708 0.01915002\n",
      " 0.01548517 0.01994312 0.01508227 0.01527628 0.02465219 0.0576337\n",
      " 0.04204767 0.03771614 0.02803523 0.01893126 0.01942357 0.01787955\n",
      " 0.01173754 0.01840504 0.02042466 0.05217232 0.04651157 0.02309647\n",
      " 0.02403621 0.0241137  0.0263937  0.01815679 0.0165982  0.01764283\n",
      " 0.01872486 0.05691597 0.07527732 0.03647905 0.02458594 0.02841208\n",
      " 0.03576404 0.02495988 0.02684662 0.02430442 0.03416195 0.07597276\n",
      " 0.09982936 0.06858351 0.05217612 0.05397278 0.04343852 0.04633578\n",
      " 0.03582176 0.04465913 0.0505885  0.10846861]\n",
      "score [0.03046557 0.03983117 0.04459144 0.04907807 0.03810293 0.04369583\n",
      " 0.05225766 0.04668823 0.06821933 0.09038692 0.03232761 0.03914151\n",
      " 0.03413606 0.02357014 0.02003576 0.01952482 0.01978173 0.03655854\n",
      " 0.03097744 0.07036351 0.0320508  0.04613395 0.02963636 0.01964573\n",
      " 0.03951283 0.02077736 0.02404025 0.03027974 0.03484295 0.08319351\n",
      " 0.02469535 0.01503875 0.02060689 0.01574777 0.02692018 0.02359101\n",
      " 0.02232479 0.01134274 0.04258066 0.07562848 0.02652322 0.02257832\n",
      " 0.01900218 0.01939881 0.02166518 0.01177339 0.01819206 0.02049454\n",
      " 0.02237685 0.04921813 0.03855741 0.01436107 0.02260997 0.03021691\n",
      " 0.01748023 0.02556794 0.01738524 0.02477993 0.02476309 0.04665136\n",
      " 0.0387566  0.03861019 0.02082434 0.02280417 0.01497354 0.02671288\n",
      " 0.01730237 0.0236948  0.02693342 0.05486206 0.06178666 0.03009503\n",
      " 0.02102049 0.0237419  0.02498337 0.02769893 0.02078257 0.01873314\n",
      " 0.0227972  0.05231623 0.06747365 0.03631845 0.03337997 0.02958554\n",
      " 0.03358071 0.0270483  0.02307736 0.02076622 0.02753057 0.07389373\n",
      " 0.09707573 0.06688872 0.06635788 0.04876571 0.04278905 0.05371002\n",
      " 0.04601424 0.04997468 0.05832925 0.13262038]\n"
     ]
    }
   ],
   "source": [
    "# why argmax(1)? split cannot simply handle multidimension y. \n",
    "# ref: https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\n",
    "for i, (train_index, val_index) in enumerate(k_fold.split(X, y.argmax(1))):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    x_train_kf, x_val_kf = X[train_index], X[val_index]\n",
    "    y_train_kf, y_val_kf = y[train_index], y[val_index]\n",
    "    #print(x_train_kf)\n",
    "    #print(y_train_kf)\n",
    "    regr.fit(x_train_kf, y_train_kf) # fit the model\n",
    "    nb_val = regr.predict(x_val_kf) # predict based on current model -> use validation data for evaluation\n",
    "    print('score', r2_score(y_val_kf, nb_val, multioutput='raw_values')) # get r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [ 6.42842234e+11 -5.37223107e+10 -1.79913453e+12 -4.61136967e+11\n",
      "  3.53936004e+11  2.27426179e+12 -1.73154084e+11 -7.10340985e+10\n",
      "  3.48134515e+12 -1.43559265e+11 -1.27855390e+12  1.68849061e+12\n",
      " -2.20133208e+11 -5.58587131e+11 -4.38254164e+11 -1.25390488e+11\n",
      " -1.83475970e+10  1.30175531e+11  8.34180861e+11 -1.16500913e+12\n",
      "  9.78914321e+11  2.71249650e+12 -1.14747634e+11 -9.26587890e+10\n",
      "  3.01645083e+11  1.19409811e+10 -1.35804795e+11 -2.28286161e+11\n",
      " -7.98258975e+11 -1.64882678e+12 -6.98231552e+11 -6.13130900e+11\n",
      " -3.06396040e+11  5.97839921e+09 -7.13916067e+10 -5.91618591e+08\n",
      "  1.92257809e+11 -6.56470750e+11 -2.70230638e+12  4.58511210e+10\n",
      " -2.64287090e+12 -1.25703672e+11 -4.32988861e+11 -4.08094889e+11\n",
      " -1.37866461e+11  3.06114247e+11 -1.92727646e+12  1.13888488e+11\n",
      " -3.33188805e+11 -1.05075536e+12 -2.35892462e+11  1.78789727e+10\n",
      " -6.62164979e+11  3.14165811e+11 -5.80227668e+11 -1.87567628e+11\n",
      " -2.88514480e+12  1.69964675e+12 -2.03421168e+12 -4.09156185e+11\n",
      " -7.03289846e+11  5.02964806e+11 -1.06342880e+11  8.07485898e+11\n",
      "  1.05120683e+12  3.65165853e+11 -5.30493200e+10 -1.50473426e+11\n",
      " -1.34022586e+12  2.96088937e+11  6.63378618e+11  4.32673174e+11\n",
      " -3.99333002e+11  1.24933781e+12 -3.27534471e+11 -3.40202417e+10\n",
      "  5.13301399e+12 -8.18997397e+11 -6.40558247e+11  6.86453641e+12\n",
      "  3.79739746e+12  1.27091045e+12 -7.24015606e+11  5.05890586e+12\n",
      " -3.98157415e+10 -1.62557596e+12 -4.81725101e+11  4.47633058e+10\n",
      "  2.12869891e+12 -2.02198140e+12  1.21396923e+12 -5.84496678e+11\n",
      " -5.16049442e+11 -2.32075303e+12 -2.33985374e+11 -7.12187682e+11\n",
      " -7.08011638e+11 -1.13255214e+12 -3.13684617e+12  4.51542108e+11]\n",
      "Coef:  [[ 3.47356993e+08  3.47356993e+08  3.47356993e+08 ... -8.34439410e+10\n",
      "  -8.34439410e+10 -8.34439410e+10]\n",
      " [ 1.02298606e+09  1.02298606e+09  1.02298606e+09 ... -3.88396188e+09\n",
      "  -3.88396188e+09 -3.88396188e+09]\n",
      " [ 5.36373275e+09  5.36373275e+09  5.36373275e+09 ...  2.13191072e+11\n",
      "   2.13191072e+11  2.13191072e+11]\n",
      " ...\n",
      " [-3.56610570e+09 -3.56610570e+09 -3.56610570e+09 ...  1.48628863e+11\n",
      "   1.48628863e+11  1.48628863e+11]\n",
      " [-4.71915378e+09 -4.71915378e+09 -4.71915378e+09 ...  3.72765622e+11\n",
      "   3.72765622e+11  3.72765622e+11]\n",
      " [ 7.54259812e+08  7.54259812e+08  7.54259812e+08 ... -7.20943364e+10\n",
      "  -7.20943364e+10 -7.20943364e+10]]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: ', regr.intercept_)\n",
    "print('Coef: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recoding MSE: \n",
      " [0.00404244 0.00559125 0.00572185 0.00592461 0.0060854  0.00575378\n",
      " 0.00687736 0.00683035 0.00954174 0.01129163 0.00433625 0.00377508\n",
      " 0.00424186 0.00383889 0.00392859 0.00457338 0.00457303 0.00518591\n",
      " 0.0092419  0.00976367 0.00624487 0.00475567 0.00526215 0.00443191\n",
      " 0.00417205 0.00470989 0.00551577 0.00639815 0.0088467  0.01143591\n",
      " 0.00545276 0.00486868 0.00494307 0.0049589  0.00537568 0.00482319\n",
      " 0.00531377 0.00715641 0.00868733 0.00964032 0.00754093 0.00525846\n",
      " 0.00484981 0.00527137 0.0059622  0.00495944 0.00594933 0.00767341\n",
      " 0.00880387 0.01083834 0.00788778 0.00545163 0.00664193 0.00600162\n",
      " 0.00528004 0.0059326  0.00643038 0.0075242  0.010256   0.01125534\n",
      " 0.00986106 0.00756913 0.00898413 0.00612098 0.00660619 0.0062944\n",
      " 0.00869929 0.00801322 0.01074506 0.01302425 0.01258533 0.00931982\n",
      " 0.00950785 0.00861138 0.0086437  0.00773796 0.00915085 0.0106507\n",
      " 0.01452287 0.01622982 0.01620957 0.01549964 0.01434503 0.0127282\n",
      " 0.01306355 0.01139402 0.01418044 0.01389043 0.02020825 0.0228688\n",
      " 0.01987008 0.01622471 0.01498104 0.01311733 0.01307424 0.01361569\n",
      " 0.01559904 0.01502199 0.02375646 0.02282426]\n",
      "recoding error std:\n",
      " [0.06357817 0.07476941 0.07564289 0.07697042 0.07800724 0.07585309\n",
      " 0.08292929 0.08263946 0.09768125 0.10626014 0.06584997 0.06144129\n",
      " 0.06512947 0.06195764 0.06267797 0.06762629 0.06762104 0.07200895\n",
      " 0.0961312  0.09881105 0.07901906 0.06895898 0.07254054 0.06657227\n",
      " 0.06458681 0.06862798 0.07426762 0.07998488 0.09405469 0.10693157\n",
      " 0.07383922 0.06977526 0.0703065  0.07041892 0.07331662 0.06944817\n",
      " 0.07289418 0.08459358 0.09320478 0.09818498 0.08683852 0.07251469\n",
      " 0.06963187 0.07260293 0.07720933 0.07042328 0.07713187 0.0875972\n",
      " 0.09382768 0.10410734 0.08881318 0.0738302  0.08149703 0.07747012\n",
      " 0.07266385 0.07701894 0.0801844  0.08674205 0.10127097 0.10608989\n",
      " 0.09930264 0.08699976 0.09477665 0.07823411 0.08127788 0.07933724\n",
      " 0.09326244 0.08951661 0.10365623 0.11412376 0.11218411 0.09653853\n",
      " 0.09750548 0.09279749 0.0929712  0.0879628  0.09566007 0.1032022\n",
      " 0.12051086 0.12738813 0.12731415 0.1244969  0.11977065 0.11281771\n",
      " 0.11429359 0.10674214 0.11908162 0.11785755 0.14215525 0.15122432\n",
      " 0.14096012 0.12737548 0.1223914  0.11452992 0.1143414  0.11668538\n",
      " 0.12489327 0.12256317 0.15411849 0.1510756 ]\n",
      "score [0.03203145 0.04176499 0.05030287 0.0539393  0.04987346 0.04499007\n",
      " 0.04626941 0.04648367 0.06751858 0.09415835 0.03687275 0.03817174\n",
      " 0.03494648 0.02191502 0.03382236 0.03199867 0.03205754 0.03639794\n",
      " 0.03581596 0.07553234 0.04618723 0.03192197 0.02228771 0.03308644\n",
      " 0.03006921 0.03199017 0.02608696 0.02370255 0.03487227 0.09093969\n",
      " 0.03398506 0.03655348 0.02183642 0.01870178 0.02664414 0.02747783\n",
      " 0.02119811 0.032287   0.04255273 0.07066711 0.04227875 0.03969158\n",
      " 0.02209955 0.02902016 0.02773881 0.02761687 0.02981359 0.02399437\n",
      " 0.02467616 0.0614868  0.04956713 0.03736761 0.02815429 0.02129272\n",
      " 0.02740667 0.02510196 0.01877578 0.01966437 0.02879037 0.04852123\n",
      " 0.04509328 0.03146795 0.02979827 0.02414009 0.01995665 0.02559811\n",
      " 0.02119714 0.01573964 0.02927239 0.05581784 0.05898164 0.03226166\n",
      " 0.02221971 0.02591178 0.02226623 0.02727557 0.021508   0.02141544\n",
      " 0.02804529 0.0531535  0.07436902 0.03934885 0.0340717  0.03197906\n",
      " 0.03031508 0.02755466 0.0301867  0.02222325 0.03364626 0.0713754\n",
      " 0.10068222 0.0635701  0.0544057  0.05224978 0.04245066 0.05142939\n",
      " 0.05422905 0.05170136 0.06972056 0.12445091]\n"
     ]
    }
   ],
   "source": [
    "predic_X_test = regr.predict(X_test)\n",
    "\n",
    "recoding_error = y_test - predic_X_test # true - estimate\n",
    "print('recoding MSE: \\n', np.mean(recoding_error**2, axis=0))\n",
    "print('recoding error std:\\n', np.std(recoding_error, axis=0))      \n",
    "print('score', r2_score(y_test, predic_X_test, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_X_df_test = DataFrame(predic_X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00280762, -0.00022888, -0.00024414, ...,  0.01855469,\n",
       "         0.06884766,  0.02380371],\n",
       "       [ 0.01013184,  0.02297974,  0.00805664, ...,  0.01611328,\n",
       "         0.00390625, -0.0010376 ],\n",
       "       [-0.00378418, -0.00576782, -0.00317383, ...,  0.05371094,\n",
       "         0.11572266,  0.04046631],\n",
       "       ...,\n",
       "       [-0.0032959 , -0.0045929 , -0.00439453, ...,  0.09985352,\n",
       "         0.0625    ,  0.07116699],\n",
       "       [-0.00415039, -0.00595093, -0.00561523, ...,  0.03173828,\n",
       "         0.13916016,  0.16516113],\n",
       "       [ 0.00598145,  0.01085663,  0.02587891, ...,  0.00317383,\n",
       "         0.00439453,  0.00457764]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic_X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot in below is different from 'recoding_KRR.ipynb'. This is RBF(belief) to RBF(belief), and 'recoding_KRR.ipynb' is belief to belief. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Recoding')"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot: compare raw data vs prediction\n",
    "plt.scatter(y_test, predic_X_test, s=0.1, c='blue', marker='o')\n",
    "plt.xlabel('transformed belief (true)')\n",
    "plt.ylabel('transformed belief (prediction)')\n",
    "plt.title('Recoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#neural estimate of belief using current linear regression model\\nnb= regr.predict(r_df) \\nnb_df = DataFrame(nb, columns = bb_df.columns)\\n#save neural estimate belief\\nnb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#neural estimate of belief using current linear regression model\n",
    "nb= regr.predict(r_df) \n",
    "nb_df = DataFrame(nb, columns = bb_df.columns)\n",
    "#save neural estimate belief\n",
    "nb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
