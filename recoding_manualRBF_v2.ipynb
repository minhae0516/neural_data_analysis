{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "updated 2019-08-08 \n",
    "written by Minhae Kwon\n",
    "\n",
    "- `recoding`: Estimate the next belief from current belief and observations\n",
    "    - input:\n",
    "        - if you use POMDP data (for now): `recoding_pomdp_all_prev_df.csv` and `recoding_pomdp_all_now_df.csv`\n",
    "        - ideally with neural data: `recoding_neural_all_prev_df.csv` and `recoding_neural_all_now_df.csv`\n",
    "    - output: `recoding_belief_results_df.csv` (estimated future belief)\n",
    "    - method: Autoregression - this is linear regression between two time steps. \n",
    "    - there are two versions in codes:\n",
    "        -`recoding_wo_RBF.ipynb`: no RBF is used. \n",
    "        - `recoding_KRR.ipynb`: RBF is used using sklearn built-in function: [Kernel Ridge Regression (kernel ='rbf')](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html). \n",
    "        (Warning: this code runs pretty slow compared to others. So if you need to handle big data size, plan in advance!)\n",
    "        - `recoding_manualRBF.ipynb`: RBF is manually coded by me. So we can customize center locations for nonlinear transform. \n",
    "        Everything is the same as `recoding_wo_RBF.ipynb` but RBF.\n",
    "        - `recoding_KRR.ipynb` works the best, and pretty good!\n",
    "\n",
    "ref: https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n",
    "https://scikit-learn.org/stable/auto_examples/plot_kernel_ridge_regression.html#sphx-glr-auto-examples-plot-kernel-ridge-regression-py\n",
    "\n",
    "ref: https://chrisalbon.com/machine_learning/linear_regression/linear_regression_using_scikit-learn/\n",
    "     https://datatofish.com/multiple-linear-regression-python/\n",
    "\n",
    "cross validate score: Coefficient of determination\n",
    "https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\"\"\"\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "#bb_df = read_csv('./data/bb_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_prev = read_csv('./data/recoding_pomdp_all_prev_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "bb_df_now = read_csv('./data/recoding_pomdp_all_now_df.csv') #behavior belief =[belief for box1, beleif for box2]\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.2  # ratio of test data set \n",
    "N_SPLITS = 10 # \"K\" in K-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bb_df_prev #.to_numpy()\n",
    "y_raw = bb_df_now[['behavior_belief1', 'behavior_belief2']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF(X_set, centers, gamma):\n",
    "    \"\"\"\n",
    "    gamma = 0.01: hard indicator\n",
    "    gamma = 0.1: soft indicator\n",
    "    \"\"\"\n",
    "    X_RBF_set = np.ones((X_set.shape[0], centers.shape[0])) # number of data set * number of center ponts\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set[i] #i-th data\n",
    "        X_RBF = np.exp(-1*1/gamma/2*np.linalg.norm(X-centers,2, axis = 1)**2)        \n",
    "        X_RBF_set[i] = X_RBF/np.sum(X_RBF)# divided by total sum -> make total sum 1\n",
    "        #print(X_RBF/np.sum(X_RBF))\n",
    "    return X_RBF_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_raw = data[['behavior_belief1', 'behavior_belief2']].to_numpy()#[:1000] # for time constraint, I tested only 1000 data points\n",
    "\n",
    "a_raw = data['action'].to_numpy()#[:1000]\n",
    "loc_raw = data['location'].to_numpy()#[:1000]\n",
    "rwd_raw = data['reward'].to_numpy()\n",
    "clr_raw = data[['color 1', 'color 2']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "b_center = np.linspace(0.05,1.05,11)[:10]\n",
    "a_center = np.array([0,1,2,3,4])\n",
    "loc_center = np.array([0, 1, 2])\n",
    "rwd_center = np.array([0, 1])\n",
    "clr_center = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# make distance =1 for belief\n",
    "nb_raw = nb_raw*10\n",
    "b_center = b_center*10\n",
    "y_raw = y_raw*10\n",
    "\n",
    "centers_a = []\n",
    "centers_b = []\n",
    "centers_loc =[]\n",
    "centers_rwd = []\n",
    "centers_clr =[]\n",
    "\n",
    "\n",
    "for i in itertools.product(b_center,b_center):\n",
    "    centers_b.append(i)\n",
    "for j in itertools.product(loc_center):\n",
    "    centers_loc.append(j)\n",
    "for k in itertools.product(rwd_center):\n",
    "    centers_rwd.append(k)\n",
    "for c in itertools.product(clr_center, clr_center):\n",
    "    centers_clr.append(c)\n",
    "for l in itertools.product(a_center):\n",
    "    centers_a.append(l)\n",
    "    \n",
    "centers_b = np.array(centers_b)\n",
    "centers_loc = np.array(centers_loc)\n",
    "centers_rwd = np.array(centers_rwd)\n",
    "centers_clr = np.array(centers_clr)\n",
    "centers_a = np.array(centers_a)\n",
    "\n",
    "# nonlinear transform using RBF: belief and location are transformed individually\n",
    "# gamma in here is the variance term in gaussian equation\n",
    "nb = RBF(nb_raw, centers_b, gamma=0.1) \n",
    "loc = RBF(loc_raw, centers_loc, gamma=0.01) # very small gamma to act as a spike (hard indicator)\n",
    "rwd = RBF(rwd_raw, centers_rwd, gamma=0.01) # very small gamma to act as a spike (hard indicator)\n",
    "clr = RBF(clr_raw, centers_clr, gamma=0.01)# very small gamma to act as a spike (hard indicator)\n",
    "a = RBF(a_raw, centers_a, gamma=0.01)# very small gamma to act as a spike (hard indicator)\n",
    "y = RBF(y_raw, centers_b, gamma=0.1) \n",
    "\n",
    "\n",
    "nb_all = np.concatenate((nb, a, loc, rwd, clr),axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_set=[]\n",
    "X_set =  np.array([[1.,1.],[1.5, 1.5]])\n",
    "X_set.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb = RBF(X_set, centers_b, gamma=0.1) \n",
    "print(nb)\n",
    "#print('sum:',np.sum(nb,axis=1))\n",
    "nb*(nb>0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nb_all\n",
    "y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there are 3 types of data: test data, train data, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(n_jobs = -1) # linear regression is used for encoding process\n",
    "#regr = KernelRidge(alpha=0.01, gamma=0.1, kernel='rbf') # linear regression(small gamma) with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use only train data \n",
    "# why use StratifiedKFold?: The folds are made by preserving the percentage of samples for each class.\n",
    "k_fold = StratifiedKFold(n_splits=N_SPLITS) # seperate train data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.03811023 0.04806983 0.06444749 0.06399676 0.06152287 0.05082249\n",
      " 0.05950449 0.05906392 0.0915198  0.1012306  0.04706873 0.01535377\n",
      " 0.02488435 0.0281793  0.01427265 0.00820073 0.02337635 0.02652535\n",
      " 0.03443275 0.0561533  0.04172704 0.02868157 0.02385559 0.03162213\n",
      " 0.0273007  0.02858289 0.03378769 0.02195777 0.04482644 0.07017946\n",
      " 0.05460876 0.04198005 0.0248426  0.02100108 0.02339757 0.01466287\n",
      " 0.02027835 0.01141037 0.02736322 0.05874045 0.05051096 0.02976517\n",
      " 0.02301953 0.02943751 0.01717182 0.0210974  0.03026822 0.0254197\n",
      " 0.024177   0.06252924 0.05187586 0.02130971 0.02294502 0.03001928\n",
      " 0.03383404 0.02073136 0.01362732 0.02000547 0.03117669 0.0596725\n",
      " 0.04784719 0.02391429 0.02183016 0.01840823 0.0152888  0.0233036\n",
      " 0.01697975 0.02570297 0.02534775 0.04688384 0.06611645 0.02685652\n",
      " 0.02381637 0.01161523 0.02180136 0.01982202 0.0136895  0.01865295\n",
      " 0.02222845 0.06688955 0.08595242 0.04001399 0.03173349 0.02426581\n",
      " 0.03047813 0.02697895 0.0243785  0.02828156 0.03588778 0.08141296\n",
      " 0.10635712 0.07096785 0.04487686 0.05200434 0.04364277 0.05405568\n",
      " 0.04593157 0.04485906 0.05415995 0.12040049]\n",
      "score [0.02861083 0.05375291 0.06004361 0.0411939  0.0473821  0.04848184\n",
      " 0.06961495 0.07057577 0.07582333 0.12550535 0.0411635  0.03909991\n",
      " 0.02217034 0.03085854 0.02751701 0.04998832 0.03076832 0.02421597\n",
      " 0.03985597 0.07544677 0.04036904 0.03302421 0.02822751 0.03343494\n",
      " 0.03757225 0.02496911 0.02753325 0.02915971 0.04543352 0.09195294\n",
      " 0.04432984 0.02559928 0.03597955 0.01148004 0.01976185 0.02621305\n",
      " 0.02002986 0.03634977 0.03435143 0.04845153 0.0447371  0.03782527\n",
      " 0.02535297 0.02381745 0.02346422 0.01391576 0.02447095 0.02067411\n",
      " 0.02639539 0.07277019 0.05385232 0.02878034 0.02298884 0.01733739\n",
      " 0.0117285  0.01687788 0.01638126 0.02551662 0.02886958 0.05090746\n",
      " 0.04546789 0.03596026 0.01108329 0.02429153 0.02759676 0.01804286\n",
      " 0.01223886 0.02642538 0.02324243 0.06138438 0.05835517 0.02614732\n",
      " 0.02467973 0.02271461 0.01883138 0.01484348 0.02121668 0.01391581\n",
      " 0.02143467 0.05134811 0.09793518 0.04656265 0.03636952 0.02515939\n",
      " 0.01955872 0.0269135  0.02847523 0.02158272 0.03768077 0.07891896\n",
      " 0.12603193 0.06673747 0.06866464 0.05687918 0.04915994 0.04172516\n",
      " 0.04035935 0.0562007  0.06086748 0.11029883]\n",
      "score [0.03570065 0.0483415  0.05579937 0.05500933 0.05234481 0.0532005\n",
      " 0.07122154 0.07734617 0.09372559 0.11223594 0.03766078 0.03390758\n",
      " 0.02628851 0.01401873 0.03155767 0.0499857  0.02370157 0.0319227\n",
      " 0.05199566 0.06338934 0.04612005 0.02665011 0.02633381 0.03124997\n",
      " 0.03469814 0.02373003 0.0278834  0.03251361 0.04326927 0.07704218\n",
      " 0.06196735 0.03192145 0.02103626 0.02447592 0.01249914 0.03174709\n",
      " 0.02229154 0.0239273  0.03300672 0.0565361  0.05118817 0.0357928\n",
      " 0.01897072 0.02458233 0.02193909 0.02265048 0.02104281 0.02243331\n",
      " 0.02565533 0.05715125 0.05561835 0.03533557 0.02714446 0.02593041\n",
      " 0.00685379 0.01068873 0.02266395 0.02213782 0.02607179 0.0615208\n",
      " 0.0582925  0.03444572 0.0288322  0.03241077 0.01965474 0.01476702\n",
      " 0.01714895 0.02112715 0.02380815 0.05859119 0.06543357 0.02674109\n",
      " 0.02604664 0.01854703 0.02491927 0.02747538 0.01496037 0.01974863\n",
      " 0.03017354 0.06202184 0.09012302 0.0408714  0.02736025 0.03149552\n",
      " 0.02713652 0.02240111 0.02663472 0.02571183 0.03075238 0.0699664\n",
      " 0.11762857 0.06220361 0.0540597  0.05995011 0.04479881 0.04737011\n",
      " 0.05362059 0.05061503 0.06236333 0.12248142]\n",
      "score [0.03181542 0.04367606 0.05845467 0.06308377 0.05439707 0.04939515\n",
      " 0.05443041 0.06972008 0.08474665 0.1045226  0.05275699 0.02426898\n",
      " 0.04446232 0.03186524 0.02269971 0.05290085 0.0248763  0.03159274\n",
      " 0.03124692 0.07679068 0.03793489 0.02560473 0.01410211 0.02012801\n",
      " 0.03391651 0.02836303 0.02636512 0.0325262  0.03632882 0.08937637\n",
      " 0.03674253 0.01816506 0.03394875 0.01350535 0.0156451  0.01572639\n",
      " 0.03356557 0.03822076 0.02738518 0.07579084 0.04965716 0.03452824\n",
      " 0.03023169 0.0273467  0.022684   0.02993448 0.02536305 0.02957824\n",
      " 0.02328407 0.0468028  0.0582177  0.02912351 0.0167281  0.01810899\n",
      " 0.02423242 0.02141534 0.02252247 0.01081088 0.01941074 0.06786868\n",
      " 0.05583691 0.04355296 0.03157285 0.01857282 0.02674987 0.01681046\n",
      " 0.01840714 0.02494287 0.03403341 0.06328632 0.06507761 0.03029185\n",
      " 0.02144862 0.01643573 0.02102167 0.03769627 0.01293916 0.0099097\n",
      " 0.03244608 0.05087788 0.08833251 0.02889672 0.03773411 0.0252044\n",
      " 0.01628829 0.02921634 0.02566065 0.01802873 0.03446278 0.07373196\n",
      " 0.0941147  0.06780145 0.05427462 0.05557279 0.04286238 0.0508016\n",
      " 0.03646952 0.05325489 0.06529976 0.13629319]\n",
      "score [0.02784543 0.05488689 0.05287707 0.04356038 0.04729888 0.06192332\n",
      " 0.05675143 0.05418207 0.07709182 0.10685349 0.03875632 0.02715138\n",
      " 0.04796656 0.02697261 0.02353971 0.04069004 0.02279717 0.02700846\n",
      " 0.03592066 0.0810813  0.03029441 0.03387655 0.01618534 0.02699144\n",
      " 0.03095366 0.04020644 0.02372053 0.02100194 0.03908126 0.07472249\n",
      " 0.04051712 0.02118637 0.01333887 0.03374627 0.01453196 0.02349872\n",
      " 0.02267689 0.02330682 0.02882545 0.06135026 0.05643181 0.02873989\n",
      " 0.02385391 0.01083167 0.02248143 0.0234954  0.02116548 0.03292813\n",
      " 0.01779643 0.0517145  0.04580126 0.02407733 0.02880088 0.03034214\n",
      " 0.02352255 0.01236268 0.02123555 0.02332325 0.02931193 0.0496067\n",
      " 0.05823125 0.03957734 0.03173057 0.02219059 0.02457709 0.0233839\n",
      " 0.02021674 0.02014531 0.02681814 0.05246542 0.06431508 0.03065468\n",
      " 0.01646527 0.01852643 0.01332705 0.02361827 0.0200074  0.01947931\n",
      " 0.02797602 0.04658873 0.09203736 0.03692314 0.02795153 0.02995329\n",
      " 0.02830634 0.02466034 0.02573006 0.02724778 0.03398675 0.07276859\n",
      " 0.12017251 0.06147571 0.05743743 0.05133378 0.04011088 0.04123835\n",
      " 0.04349902 0.03604918 0.06392167 0.11146918]\n",
      "score [0.03605719 0.04364158 0.05408808 0.05498883 0.07074205 0.05973412\n",
      " 0.06653971 0.06891938 0.08333861 0.11305896 0.04682117 0.03174839\n",
      " 0.02285091 0.02109848 0.02363524 0.0238942  0.030661   0.0216483\n",
      " 0.03765185 0.06373586 0.0327465  0.03985679 0.02958604 0.03781093\n",
      " 0.04073168 0.04304379 0.02190365 0.02318616 0.0440279  0.07578548\n",
      " 0.04237869 0.02563231 0.0231842  0.02376721 0.03235615 0.02417022\n",
      " 0.02055377 0.02503875 0.03516327 0.06499104 0.03956493 0.03453427\n",
      " 0.02122842 0.0070392  0.02320655 0.0155598  0.02213897 0.03018728\n",
      " 0.0284562  0.05458362 0.04629319 0.03714117 0.01468871 0.01372073\n",
      " 0.01926025 0.01054307 0.01774292 0.03200034 0.027505   0.04509693\n",
      " 0.0609678  0.02905958 0.02512689 0.02533844 0.00643088 0.02690403\n",
      " 0.01855247 0.00835638 0.02046242 0.06182966 0.0766949  0.02795057\n",
      " 0.02659575 0.02044817 0.02801966 0.0291722  0.02202586 0.02100953\n",
      " 0.03136009 0.05249068 0.08536817 0.0335813  0.03365393 0.03061386\n",
      " 0.02340351 0.03291796 0.02385903 0.0303053  0.03329069 0.07342964\n",
      " 0.117639   0.06497205 0.05134746 0.0443309  0.05964793 0.04969279\n",
      " 0.04296642 0.04472184 0.0750042  0.12129356]\n",
      "score [0.03798205 0.05070082 0.05920607 0.06423843 0.06752012 0.0570435\n",
      " 0.05224295 0.07711374 0.08888258 0.09890593 0.04345438 0.03676271\n",
      " 0.0252822  0.01589563 0.02337041 0.00685925 0.03466412 0.02667429\n",
      " 0.04933712 0.06135541 0.04238418 0.03545445 0.02052912 0.02337914\n",
      " 0.03079551 0.0222957  0.02911137 0.03262056 0.04379906 0.07033009\n",
      " 0.04743567 0.02769349 0.01922734 0.01497174 0.02290196 0.0296443\n",
      " 0.02140388 0.03719851 0.03516663 0.06140847 0.03711118 0.04029869\n",
      " 0.02796719 0.02371959 0.01355649 0.03140962 0.01562662 0.02431365\n",
      " 0.03044257 0.05863859 0.05308956 0.04579957 0.02527101 0.01819653\n",
      " 0.02160019 0.02629891 0.02388578 0.01699253 0.01394616 0.04276455\n",
      " 0.05395885 0.03816286 0.01876661 0.02604342 0.02483055 0.01716149\n",
      " 0.0169315  0.01145473 0.03073718 0.06042948 0.06301037 0.02637808\n",
      " 0.02518299 0.02072916 0.02226134 0.03227226 0.01690627 0.02482173\n",
      " 0.02369769 0.06313697 0.08900526 0.04153438 0.03234453 0.02866973\n",
      " 0.02962025 0.02302345 0.02935175 0.02225703 0.03517627 0.06102521\n",
      " 0.11112469 0.06649182 0.05716911 0.04958005 0.04223428 0.04870023\n",
      " 0.04667527 0.04426141 0.06094537 0.12385152]\n",
      "score [0.01855893 0.03649024 0.05466704 0.06160135 0.06601791 0.05572275\n",
      " 0.05721122 0.06560773 0.09927589 0.10678802 0.04029978 0.01664199\n",
      " 0.03068761 0.02686428 0.03751726 0.04769448 0.03007486 0.03097753\n",
      " 0.03760909 0.07987767 0.04283969 0.03302698 0.02967284 0.03561655\n",
      " 0.02459565 0.0288659  0.02352759 0.02880485 0.04969094 0.08382004\n",
      " 0.05002209 0.02307913 0.02824811 0.02368607 0.03117383 0.0197277\n",
      " 0.01957671 0.02475933 0.03139246 0.06644737 0.0467981  0.02706138\n",
      " 0.01799163 0.02103933 0.03562226 0.0172321  0.01555049 0.02130377\n",
      " 0.02012011 0.07220907 0.04876701 0.04064934 0.02983753 0.02952938\n",
      " 0.01768242 0.00866537 0.02279674 0.02111218 0.02639025 0.05187578\n",
      " 0.06919788 0.0233589  0.0273581  0.02174774 0.02790483 0.0158498\n",
      " 0.02055308 0.02059588 0.02492068 0.05526366 0.06227397 0.03093529\n",
      " 0.02133839 0.01573096 0.02321431 0.02845423 0.02048449 0.01340508\n",
      " 0.02762653 0.04511295 0.08382818 0.03722943 0.03390657 0.02890944\n",
      " 0.02958755 0.03228471 0.02979117 0.01902498 0.03217618 0.07872183\n",
      " 0.10947205 0.05399594 0.05435451 0.05952387 0.04609703 0.0371213\n",
      " 0.05112012 0.04323305 0.0662035  0.13693929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.03766179 0.04889383 0.04512517 0.06333225 0.05972021 0.0398511\n",
      " 0.05333548 0.05933183 0.08971391 0.12240332 0.02961843 0.04825315\n",
      " 0.0262995  0.02804688 0.01511968 0.02845445 0.02494373 0.02085296\n",
      " 0.03844682 0.0856314  0.02831505 0.03595661 0.02697037 0.0274608\n",
      " 0.03078031 0.02546117 0.02790447 0.02553157 0.0394098  0.08362338\n",
      " 0.04966606 0.03618177 0.02975066 0.02512934 0.01485934 0.02058508\n",
      " 0.0199316  0.03173208 0.03344677 0.04483182 0.05339434 0.02760376\n",
      " 0.01672147 0.01511232 0.00863884 0.01991189 0.02046757 0.01827398\n",
      " 0.03298043 0.05444028 0.0577899  0.02464319 0.01509089 0.01908322\n",
      " 0.01528949 0.02018878 0.01585304 0.01567685 0.02562927 0.05877857\n",
      " 0.05459424 0.03742942 0.02823917 0.01878849 0.01930245 0.0184351\n",
      " 0.01261173 0.01867623 0.02155663 0.05365054 0.05076059 0.02346628\n",
      " 0.0243927  0.02434179 0.02643374 0.0182093  0.01636362 0.01789322\n",
      " 0.02000967 0.05979238 0.0996442  0.03702841 0.02352855 0.02883426\n",
      " 0.03626374 0.02504114 0.02746515 0.02583104 0.03623212 0.0801766\n",
      " 0.1183101  0.06982165 0.05318444 0.05496248 0.04525405 0.04746683\n",
      " 0.03758898 0.04677768 0.05383683 0.11440711]\n",
      "score [0.04075358 0.05092969 0.05561238 0.05937006 0.04934439 0.05222264\n",
      " 0.06563572 0.05663175 0.0884627  0.10425562 0.03961919 0.03871439\n",
      " 0.03408193 0.02354709 0.02013759 0.01971671 0.01993632 0.03662205\n",
      " 0.03103494 0.07069579 0.03629879 0.04576877 0.02966075 0.01960353\n",
      " 0.03937354 0.02065856 0.02415481 0.03103796 0.03476536 0.08460111\n",
      " 0.03191931 0.0150615  0.02065553 0.01560514 0.02678821 0.0236768\n",
      " 0.02223963 0.01123196 0.04262132 0.07663544 0.03372532 0.02272258\n",
      " 0.01919442 0.0193051  0.0220193  0.01195134 0.01866201 0.02086667\n",
      " 0.02294445 0.0502644  0.04399003 0.01422077 0.02279832 0.03059382\n",
      " 0.0173461  0.02543019 0.01764057 0.02517552 0.02568268 0.04827012\n",
      " 0.05191927 0.03901216 0.02139505 0.02309803 0.01483274 0.02657122\n",
      " 0.01764659 0.02409262 0.02814603 0.05803515 0.07639908 0.03023796\n",
      " 0.02140718 0.02377602 0.02516814 0.02759401 0.02106435 0.01982036\n",
      " 0.02407691 0.05497172 0.08519384 0.03648654 0.03398058 0.02927201\n",
      " 0.03513387 0.02771822 0.02420073 0.02230922 0.0297472  0.078053\n",
      " 0.11692035 0.06704812 0.06651277 0.05006826 0.04271199 0.0546683\n",
      " 0.04757643 0.05284256 0.06128053 0.13861903]\n"
     ]
    }
   ],
   "source": [
    "# why argmax(1)? split cannot simply handle multidimension y. \n",
    "# ref: https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\n",
    "for i, (train_index, val_index) in enumerate(k_fold.split(X, y.argmax(1))):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    x_train_kf, x_val_kf = X[train_index], X[val_index]\n",
    "    y_train_kf, y_val_kf = y[train_index], y[val_index]\n",
    "    #print(x_train_kf)\n",
    "    #print(y_train_kf)\n",
    "    regr.fit(x_train_kf, y_train_kf) # fit the model\n",
    "    nb_val = regr.predict(x_val_kf) # predict based on current model -> use validation data for evaluation\n",
    "    print('score', r2_score(y_val_kf, nb_val, multioutput='raw_values')) # get r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [ 3.52632647e+10 -1.01397295e+12 -2.67106492e+12 -1.85903979e+12\n",
      " -6.43538769e+11 -9.29089674e+11 -7.92950691e+11 -1.42939491e+12\n",
      "  4.86134167e+11 -1.82020083e+12 -4.88095362e+11  1.43262697e+12\n",
      " -1.42462105e+11 -6.68489649e+11  1.53518166e+10 -4.95386803e+11\n",
      " -1.37044450e+11  6.46272277e+11  2.68873533e+12 -6.63563645e+11\n",
      " -1.10329161e+12  1.22185755e+12  4.00121993e+11 -1.75535392e+11\n",
      "  2.20239914e+11 -3.10380500e+11  4.81484094e+10  5.59327162e+11\n",
      " -8.78476748e+11 -5.66254908e+11 -5.20725692e+11  2.16762888e+10\n",
      " -5.96258428e+10  5.17113346e+10  3.24036491e+11  1.52671795e+11\n",
      "  2.67712106e+11  4.69937716e+11 -1.49616640e+12 -2.13941018e+12\n",
      " -5.45563360e+11 -4.03469541e+11 -3.12375254e+11  5.95106872e+11\n",
      " -3.86697059e+11  2.67356299e+11  2.77836430e+12  2.41616440e+11\n",
      " -1.13297528e+11 -6.87310594e+11  2.99301602e+11 -3.66223156e+11\n",
      " -1.82742394e+11 -6.28579741e+11  3.75109032e+11 -2.23373365e+11\n",
      " -2.80770033e+11  4.68026198e+10  9.81417799e+11  4.52096045e+11\n",
      "  9.69156197e+11 -4.05223970e+11 -1.88606702e+12  1.81612142e+12\n",
      "  1.88364597e+12  9.38243179e+10 -3.31789260e+11 -9.96042263e+10\n",
      " -1.07736811e+12  1.60192622e+11  2.77763413e+12  6.83688561e+11\n",
      " -4.16659198e+11  2.41891282e+12 -5.15751562e+11 -4.22933102e+11\n",
      "  1.60733510e+12 -4.88485019e+12 -4.98196524e+11  2.20694011e+12\n",
      "  4.76023095e+12  1.72961520e+12 -1.22588325e+12 -3.42142665e+11\n",
      " -7.89616644e+11 -1.90282315e+12 -6.09471355e+11 -1.94241022e+11\n",
      "  2.10784767e+12  6.14690185e+12  2.81445518e+12  1.38175761e+12\n",
      " -1.30943640e+12 -2.45011381e+12 -1.10739773e+11 -4.24493687e+11\n",
      "  2.74215091e+11 -3.75839261e+11 -3.93769377e+12  4.34031408e+11]\n",
      "Coef:  [[ 6.43735920e+08  6.43735920e+08  6.43735920e+08 ... -3.17041569e+09\n",
      "  -3.17041569e+09 -3.17041569e+09]\n",
      " [ 1.25424400e+09  1.25424400e+09  1.25424400e+09 ...  1.37743247e+11\n",
      "   1.37743247e+11  1.37743247e+11]\n",
      " [ 5.71071507e+09  5.71071507e+09  5.71071507e+09 ...  3.66677833e+11\n",
      "   3.66677833e+11  3.66677833e+11]\n",
      " ...\n",
      " [-4.12535184e+09 -4.12535184e+09 -4.12535184e+09 ...  6.74845306e+10\n",
      "   6.74845306e+10  6.74845306e+10]\n",
      " [-5.38382306e+09 -5.38382306e+09 -5.38382306e+09 ...  5.25019655e+11\n",
      "   5.25019655e+11  5.25019655e+11]\n",
      " [-3.72310972e+08 -3.72310972e+08 -3.72310972e+08 ... -6.80017901e+10\n",
      "  -6.80017901e+10 -6.80017901e+10]]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: ', regr.intercept_)\n",
    "print('Coef: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recoding MSE: \n",
      " [0.00400893 0.00552889 0.00564839 0.00584733 0.00600076 0.00569662\n",
      " 0.00678192 0.0067554  0.00937278 0.01109783 0.00431842 0.00377619\n",
      " 0.00424162 0.0038389  0.00392844 0.00457288 0.00457329 0.00518609\n",
      " 0.00923716 0.00975178 0.0061929  0.00475326 0.00526256 0.00443168\n",
      " 0.00417081 0.00470967 0.00551509 0.00639866 0.00884289 0.01142529\n",
      " 0.00542771 0.00486808 0.00494272 0.00495875 0.00537613 0.00482237\n",
      " 0.00531316 0.007154   0.00868228 0.00962533 0.00747588 0.005257\n",
      " 0.00484913 0.00527103 0.00596172 0.00495898 0.00594763 0.00766616\n",
      " 0.00879783 0.01082875 0.00782763 0.00545076 0.00663987 0.00600067\n",
      " 0.00528031 0.00593031 0.00642729 0.00752125 0.01024988 0.01123702\n",
      " 0.00973886 0.0075676  0.00897965 0.00612141 0.00660551 0.00629136\n",
      " 0.00869782 0.00800759 0.01073237 0.01300806 0.01245918 0.00931942\n",
      " 0.00950262 0.00861168 0.00863912 0.00773466 0.00913888 0.01063715\n",
      " 0.01449596 0.01616258 0.01591518 0.01548344 0.01433896 0.01272284\n",
      " 0.01304902 0.01138727 0.01417072 0.01387316 0.02015113 0.02275924\n",
      " 0.01947744 0.01621302 0.01497807 0.01310854 0.01305757 0.01360139\n",
      " 0.01558165 0.01499209 0.02365603 0.02267824]\n",
      "recoding error std:\n",
      " [0.06331392 0.07435003 0.07515434 0.07646702 0.07746328 0.07547566\n",
      " 0.08235215 0.08218373 0.09681301 0.1053448  0.06571392 0.0614499\n",
      " 0.06512759 0.06195762 0.06267696 0.06762279 0.06762307 0.07200994\n",
      " 0.09610934 0.09875077 0.07868758 0.06894345 0.07254319 0.0665706\n",
      " 0.06457674 0.06862611 0.074263   0.07998828 0.09403497 0.10688286\n",
      " 0.07366859 0.06977119 0.07030425 0.07041785 0.07331981 0.06944231\n",
      " 0.07289012 0.08457902 0.09317732 0.09810857 0.08646182 0.07250457\n",
      " 0.06962652 0.07260066 0.07720712 0.07041997 0.07712027 0.08755588\n",
      " 0.0937959  0.10406129 0.08847387 0.073824   0.08148462 0.07746395\n",
      " 0.07266573 0.07700388 0.08016906 0.08672507 0.10124015 0.10600388\n",
      " 0.09868511 0.08699105 0.09475463 0.07823635 0.08127355 0.07931809\n",
      " 0.09325433 0.08948515 0.10359501 0.11405272 0.11161928 0.09653691\n",
      " 0.09747872 0.09279896 0.09294662 0.08794397 0.09559596 0.10313591\n",
      " 0.12039912 0.12713139 0.12615139 0.12443177 0.11974538 0.11279432\n",
      " 0.11422867 0.1067098  0.11904076 0.1177843  0.14195262 0.15086153\n",
      " 0.13955814 0.1273287  0.12237914 0.11449046 0.11426857 0.11662399\n",
      " 0.1248237  0.12244022 0.15379401 0.15059179]\n",
      "score [0.04005548 0.05245183 0.06249482 0.06627996 0.06308748 0.05447801\n",
      " 0.05950359 0.05694549 0.08403016 0.10970559 0.04083272 0.03788823\n",
      " 0.03500178 0.02191269 0.03385893 0.03210451 0.03200312 0.03636294\n",
      " 0.03631073 0.07665839 0.05412531 0.03241251 0.02221271 0.03313769\n",
      " 0.03035813 0.03203527 0.02620829 0.02362537 0.03528797 0.09178376\n",
      " 0.03842321 0.03667274 0.02190451 0.01873152 0.02656186 0.02764258\n",
      " 0.02131108 0.03261213 0.0431097  0.07211215 0.05053998 0.03995724\n",
      " 0.02223658 0.02908396 0.02781816 0.02770634 0.03008974 0.02491713\n",
      " 0.02534457 0.06231688 0.05681539 0.03752088 0.02845561 0.02144859\n",
      " 0.02735616 0.02547763 0.01924776 0.02004855 0.02936982 0.05007026\n",
      " 0.05692665 0.03166289 0.03028185 0.02407031 0.02005822 0.0260684\n",
      " 0.0213622  0.01643144 0.03041884 0.05699212 0.06841417 0.03230303\n",
      " 0.02275765 0.02587746 0.0227838  0.02769013 0.02278796 0.02265984\n",
      " 0.02984688 0.05707606 0.09118002 0.04035289 0.03448018 0.03238662\n",
      " 0.03139373 0.02813056 0.03085121 0.02343899 0.03637786 0.0758243\n",
      " 0.11845302 0.06424473 0.05459313 0.0528846  0.04367172 0.05242535\n",
      " 0.05528306 0.05358901 0.0736533  0.13005237]\n"
     ]
    }
   ],
   "source": [
    "predic_X_test = regr.predict(X_test)\n",
    "\n",
    "recoding_error = y_test - predic_X_test # true - estimate\n",
    "print('recoding MSE: \\n', np.mean(recoding_error**2, axis=0))\n",
    "print('recoding error std:\\n', np.std(recoding_error, axis=0))      \n",
    "print('score', r2_score(y_test, predic_X_test, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_X_df_test = DataFrame(predic_X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00298309,  0.00061035,  0.00146484, ...,  0.01678467,\n",
       "         0.07080078,  0.02587891],\n",
       "       [ 0.00971222,  0.02209473,  0.00585938, ...,  0.01678467,\n",
       "         0.00439453, -0.00036621],\n",
       "       [-0.00485229, -0.00598145, -0.00341797, ...,  0.05291748,\n",
       "         0.11865234,  0.04406738],\n",
       "       ...,\n",
       "       [-0.00485229, -0.0065918 , -0.00732422, ...,  0.10186768,\n",
       "         0.06494141,  0.07385254],\n",
       "       [-0.00559235, -0.00854492, -0.00878906, ...,  0.03424072,\n",
       "         0.13867188,  0.16796875],\n",
       "       [ 0.00623322,  0.01098633,  0.02587891, ...,  0.00323486,\n",
       "         0.00732422,  0.00646973]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic_X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot in below is different from 'recoding_KRR.ipynb'. This is RBF(belief) to RBF(belief), and 'recoding_KRR.ipynb' is belief to belief. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Recoding')"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot: compare raw data vs prediction\n",
    "plt.scatter(y_test, predic_X_test, s=0.1, c='blue', marker='o')\n",
    "plt.xlabel('transformed belief (true)')\n",
    "plt.ylabel('transformed belief (prediction)')\n",
    "plt.title('Recoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#neural estimate of belief using current linear regression model\\nnb= regr.predict(r_df) \\nnb_df = DataFrame(nb, columns = bb_df.columns)\\n#save neural estimate belief\\nnb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#neural estimate of belief using current linear regression model\n",
    "nb= regr.predict(r_df) \n",
    "nb_df = DataFrame(nb, columns = bb_df.columns)\n",
    "#save neural estimate belief\n",
    "nb_df.to_csv(path_or_buf='./data/nb_df.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
